{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING TRAINING DATA 🏊 🚴‍♂️ 🏃‍♀️‍➡️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_rows = 6000\n",
    "pd.options.display.max_columns = 6000\n",
    "\n",
    "# Read Data and Create Data Frames\n",
    "df_activs_raw = pd.read_csv('./data/activities.csv')\n",
    "df_injuries = pd.read_csv('./data/injuries & sicknesses.csv')\n",
    "df_max_hr_limit = pd.read_csv('../TRI_250105_Whoop-Data_Analysis/whoop data/max heart rate limit per day.csv')\n",
    "df_exert = pd.read_csv('./data/perceived exertion 2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FUNCTIONS GO HERE ######\n",
    "\n",
    "def null_count (dataframe):\n",
    "    ''' \n",
    "    This function shows for an inputted dataframe a table of all the null values per columns\n",
    "    input: your dataframe\n",
    "    output: dataframe holding the null values count per column of your dataframe\n",
    "    '''\n",
    "    null_list = dataframe.isnull().sum()\n",
    "    # Transforming the list into a dataframe \n",
    "    dataframe_nulls = pd.DataFrame(null_list)\n",
    "    dataframe_nulls.columns = ['Null Count']\n",
    "    # Filtering: only show columns where null values exist\n",
    "    dataframe_nulls_only = dataframe_nulls[dataframe_nulls[\"Null Count\"] > 0]\n",
    "    return dataframe_nulls_only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning `df_exert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exert [\"date\"] = pd.to_datetime(df_exert[\"date\"], format=\"mixed\",  dayfirst = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning `df_max_hr_limit_raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_hr_limit [\"date\"] = pd.to_datetime(df_max_hr_limit[\"date\"], format=\"mixed\",  dayfirst = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning `df_injuries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make columns lowercase\n",
    "df_injuries.columns = [x.lower() for x in df_injuries.columns]\n",
    "# Change data type of time columns\n",
    "df_injuries[\"date\"] = pd.to_datetime(df_injuries[\"date\"], format=\"mixed\",  dayfirst = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning `df_activs_raw`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing & Cleaning Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Make column names lowercase\n",
    "df_activs_raw.columns = [x.lower() for x in df_activs_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a)Dropping unneccesary columns\n",
    "df_activs_raw = df_activs_raw.drop([\n",
    "\"commute\",\n",
    "\"activity private note\",\n",
    "\"activity gear\",\n",
    "\"athlete weight\",\n",
    "\"bike weight\",\n",
    "\"elapsed time.1\",\n",
    "\"distance\",     # which should I drop distance.1 or distance, I think distance.1 also has values for indoor swimming, the other one not\n",
    "\"relative effort.1\",\n",
    "\"total work\",\n",
    "\"number of runs\",\n",
    "\"uphill time\",\n",
    "\"downhill time\",\n",
    "\"other time\",\n",
    "\"max heart rate\",\n",
    "\"type\",\n",
    "\"start time\",\n",
    "\"prefer perceived exertion\",\n",
    "\"perceived exertion\", # deleting this and later recreating it with data from different dataset\n",
    "\"commute.1\",\n",
    "\"total weight lifted\",\n",
    "\"from upload\",\n",
    "\"bike\",\n",
    "\"gear\",\n",
    "\"jump count\",\n",
    "\"total grit\",\n",
    "\"average flow\",\n",
    "\"flagged\",\n",
    "\"dirt distance\",\n",
    "\"newly explored distance\",\n",
    "\"newly explored dirt distance\",\n",
    "\"activity count\",\n",
    "\"weighted average power\", \n",
    "\"power count\",\n",
    "\"total steps\",\n",
    "\"max watts\",\n",
    "\"carbon saved\",\n",
    "\"training load\",\n",
    "\"intensity\",\n",
    "\"timer time\",\n",
    "\"total cycles\",\n",
    "\"media\",\n",
    "], axis=1)\n",
    "\n",
    "#2b)Dropping weather-related columns\n",
    "df_activs_raw = df_activs_raw.drop([\n",
    "\"weather observation time\",\n",
    "\"weather condition\",\n",
    "\"weather temperature\",\n",
    "\"apparent temperature\",\n",
    "\"dewpoint\",\n",
    "\"humidity\",\n",
    "\"weather pressure\",\n",
    "\"wind speed\",\n",
    "\"wind gust\",\n",
    "\"wind bearing\",\n",
    "\"precipitation intensity\",\n",
    "\"precipitation probability\",\n",
    "\"precipitation probability\",         \n",
    "\"precipitation type\", \"cloud cover\",                    \n",
    "\"weather visibility\",                \n",
    "\"uv index\",                        \n",
    "\"weather ozone\", \n",
    "\"sunrise time\",\n",
    "\"sunset time\",\n",
    "\"moon phase\",\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b) Rename columns\n",
    "df_activs_raw = df_activs_raw.rename({\"max heart rate.1\": \"max heart rate\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average speed\": \"avg speed mps\"}, axis=1) # renaming the columns with meters per second to later better identify them and then reformat them to km/h\n",
    "df_activs_raw = df_activs_raw.rename({\"max speed\": \"max speed mps\"}, axis=1)         # renaming the columns with meters per second to later better identify them and then reformat them to km/h\n",
    "df_activs_raw = df_activs_raw.rename({\"average elapsed speed\": \"avg elapsed speed mps\"}, axis=1)  # renaming the columns with meters per second to later better identify them and then reformat them to km/h\n",
    "df_activs_raw = df_activs_raw.rename({\"distance.1\": \"distance\"}, axis=1)\n",
    "\n",
    "# abbreviating some of the columns to make it easier to work with them\n",
    "df_activs_raw = df_activs_raw.rename({\"average grade\": \"avg grade\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average positive grade\": \"avg positive grade\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average negative grade\": \"avg negative grade\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average cadence\": \"avg cadence\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average heart rate\": \"avg heart rate\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average watts\": \"avg watts\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average temperature\": \"avg temperature\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"average grade adjusted pace\": \"avg grade adjusted pace\"}, axis=1)\n",
    "df_activs_raw = df_activs_raw.rename({\"weighted average power\": \"weighted avg power\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a) Change data type of time columns\n",
    "df_activs_raw[\"activity date\"] = pd.to_datetime(df_activs_raw[\"activity date\"], format=\"mixed\",  dayfirst = True)\n",
    "df_activs_raw[\"elapsed time\"]= pd.to_timedelta(df_activs_raw[\"elapsed time\"], unit='s')\n",
    "df_activs_raw[\"moving time\"]= pd.to_timedelta(df_activs_raw[\"moving time\"], unit='s')\n",
    "\n",
    "# Change data type of distance\n",
    "df_activs_raw[\"distance\"] = pd.to_numeric(df_activs_raw[\"distance\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3b) Changing the format of speed columns from meter per second to kilometres per hour\n",
    "df_activs_raw[\"avg speed\"] = df_activs_raw[\"avg speed mps\"] * (18/5)\n",
    "df_activs_raw[\"max speed\"] = df_activs_raw[\"max speed mps\"] * (18/5)\n",
    "df_activs_raw[\"avg elapsed speed\"] = df_activs_raw[\"avg elapsed speed mps\"] * (18/5)\n",
    "\n",
    "\n",
    "# Dropping the columns with meter per second (the new columns with kmh values stay)\n",
    "df_activs_raw = df_activs_raw.drop([\"avg speed mps\", \"max speed mps\", \"avg elapsed speed mps\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3c) Changing the  format of the distance.1 column, which holds more and better values than the other \"distance\" column, to kilometres\n",
    "df_activs_raw[\"distance\"] = df_activs_raw[\"distance\"] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) \n",
    "# Split columns and create new columns\n",
    "df_activs_raw['date'] = pd.to_datetime(df_activs_raw['activity date'], format=\"mixed\").dt.date.astype(\"datetime64[ns]\")\n",
    "#df_activs_raw['start time'] = pd.to_datetime(df_activs_raw['activity date'], format=\"mixed\").dt.time.astype(\"datetime64[ns]\")     # Uncomment this if you want finish time a clock time but then it becomes an object\n",
    "df_activs_raw['start time'] = pd.to_datetime(df_activs_raw['activity date'], format=\"mixed\").dt.time\n",
    "df_activs_raw['start time'] = pd.to_timedelta(df_activs_raw['start time'].astype(str))\n",
    "\n",
    "# create new column for finish time \n",
    "df_activs_raw['finish time'] = df_activs_raw['activity date'] + df_activs_raw['elapsed time']  \n",
    "df_activs_raw['finish time'] = pd.to_datetime(df_activs_raw['finish time'], format=\"mixed\").dt.time\n",
    "df_activs_raw['finish time'] = pd.to_timedelta(df_activs_raw['finish time'].astype(str))\n",
    "\n",
    "#df_activs_raw['finish time'] = pd.to_datetime(df_activs_raw['finish time'], format=\"mixed\").dt.time  # Uncomment this if you want finish time a clock time but then it becomes an object\n",
    "\n",
    "# create a column for sport, which should hold swim, bike, run instead of the activity type column which holds swim, ride, virtual ride, run\n",
    "df_activs_raw['sport'] = df_activs_raw['activity type']\n",
    "\n",
    "df_activs_raw['sport'] =  df_activs_raw['sport'].replace('Virtual Ride', 'Bike')\n",
    "df_activs_raw['sport'] =  df_activs_raw['sport'].replace('Ride', 'Bike')\n",
    "\n",
    "# create a column for the zone that the average heart rate during the activity was in    \n",
    "\n",
    "# Note: These HR Zones are based on a max hr of 191, which is the avg max heart rate over my 6 years of training. \n",
    "# The zone calculation is therefore an approximation. I would be better to calculate the zones based on my daily or at least yearly max heart rate. \n",
    "def get_hr_zone(hr):\n",
    "    if hr < 94:        \n",
    "        return 'below zones' \n",
    "    elif 130 <= hr < 140:\n",
    "        return 'z1'                 \n",
    "    elif 141 <= hr < 154:\n",
    "        return 'z2'                 \n",
    "    elif 155 <= hr < 167:\n",
    "        return 'z3'                 \n",
    "    elif 168 <= hr < 179:\n",
    "        return 'z4'                 \n",
    "    elif hr > 180:\n",
    "        return 'z5'\n",
    "    else:\n",
    "        return 'no hr collected'\n",
    "\n",
    "df_activs_raw['avg heart rate zone'] = df_activs_raw['avg heart rate'].apply(get_hr_zone)\n",
    "\n",
    "# create a column for the training mode, the activity was in. Either high intensity (Z3,4,5) or low intensity. We will fill the column later with values\n",
    "df_activs_raw['training mode'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>activity description</th>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative effort</th>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation gain</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation loss</th>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation low</th>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation high</th>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max grade</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg positive grade</th>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg negative grade</th>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max cadence</th>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg cadence</th>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max heart rate</th>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg heart rate</th>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg watts</th>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calories</th>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max temperature</th>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg temperature</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perceived relative effort</th>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade adjusted distance</th>\n",
       "      <td>1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool length</th>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg grade adjusted pace</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg speed</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max speed</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg elapsed speed</th>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training mode</th>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Null Count\n",
       "activity description             1369\n",
       "relative effort                   955\n",
       "filename                           85\n",
       "distance                            3\n",
       "elevation gain                    126\n",
       "elevation loss                    576\n",
       "elevation low                     546\n",
       "elevation high                    546\n",
       "max grade                          85\n",
       "avg positive grade               2051\n",
       "avg negative grade               2051\n",
       "max cadence                      1061\n",
       "avg cadence                      1030\n",
       "max heart rate                   1644\n",
       "avg heart rate                    784\n",
       "avg watts                        1592\n",
       "calories                          318\n",
       "max temperature                  2051\n",
       "avg temperature                  2000\n",
       "perceived relative effort        2022\n",
       "grade adjusted distance          1684\n",
       "pool length                      2018\n",
       "avg grade adjusted pace          2011\n",
       "avg speed                         400\n",
       "max speed                          85\n",
       "avg elapsed speed                 931\n",
       "training mode                    2051"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5) Check for missing values (use the function)\n",
    "null_count(df_activs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining rows left: 1992\n"
     ]
    }
   ],
   "source": [
    "#6a) drop all entries that are entered by WHOOP (these are basically duplicates. Activities that have been recorded on Whoop and Garmin)\n",
    "\n",
    "df_activs_raw = df_activs_raw[~df_activs_raw[\"activity name\"].str.contains(\"WHOOP Cycling\", case=False, na=False)]\n",
    "df_activs_raw = df_activs_raw[~df_activs_raw[\"activity name\"].str.contains(\"WHOOP Running\", case=False, na=False)]\n",
    "df_activs_raw = df_activs_raw[~df_activs_raw[\"activity name\"].str.contains(\"WHOOP Swimming\", case=False, na=False)]\n",
    "\n",
    "#6b)also deleting all other WHoop-Activties (which can also be duplicates of other Strava activites but with less information)\n",
    "df_activs_raw = df_activs_raw[~df_activs_raw[\"activity name\"].str.contains(\"WHOOP\", case=False, na=False)]\n",
    "\n",
    "print (f\"Number of remaining rows left: {len(df_activs_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining rows left: 1756\n"
     ]
    }
   ],
   "source": [
    "#6c) drop all entries that are hikes, crossfit and general workouts\n",
    "df_activs_raw = df_activs_raw.drop(df_activs_raw[df_activs_raw[\"activity type\"]== \"Hike\"].index)\n",
    "df_activs_raw = df_activs_raw.drop(df_activs_raw[df_activs_raw[\"activity type\"]== \"Crossfit\"].index)\n",
    "df_activs_raw = df_activs_raw.drop(df_activs_raw[df_activs_raw[\"activity type\"]== \"Workout\"].index)\n",
    "\n",
    "print (f\"Number of remaining rows left: {len(df_activs_raw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7a) Check duplicates (CLASSIC VERSION)\n",
    "df_activs_raw.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity id</th>\n",
       "      <th>activity date</th>\n",
       "      <th>activity name</th>\n",
       "      <th>activity type</th>\n",
       "      <th>activity description</th>\n",
       "      <th>elapsed time</th>\n",
       "      <th>relative effort</th>\n",
       "      <th>filename</th>\n",
       "      <th>moving time</th>\n",
       "      <th>distance</th>\n",
       "      <th>elevation gain</th>\n",
       "      <th>elevation loss</th>\n",
       "      <th>elevation low</th>\n",
       "      <th>elevation high</th>\n",
       "      <th>max grade</th>\n",
       "      <th>avg grade</th>\n",
       "      <th>avg positive grade</th>\n",
       "      <th>avg negative grade</th>\n",
       "      <th>max cadence</th>\n",
       "      <th>avg cadence</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>avg heart rate</th>\n",
       "      <th>avg watts</th>\n",
       "      <th>calories</th>\n",
       "      <th>max temperature</th>\n",
       "      <th>avg temperature</th>\n",
       "      <th>perceived relative effort</th>\n",
       "      <th>grade adjusted distance</th>\n",
       "      <th>pool length</th>\n",
       "      <th>avg grade adjusted pace</th>\n",
       "      <th>avg speed</th>\n",
       "      <th>max speed</th>\n",
       "      <th>avg elapsed speed</th>\n",
       "      <th>date</th>\n",
       "      <th>start time</th>\n",
       "      <th>finish time</th>\n",
       "      <th>sport</th>\n",
       "      <th>avg heart rate zone</th>\n",
       "      <th>training mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1913005302</td>\n",
       "      <td>2018-10-18 16:53:13</td>\n",
       "      <td>Fahrt zum Schwimmen</td>\n",
       "      <td>Ride</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 02:10:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>activities/1913005302.gpx</td>\n",
       "      <td>0 days 00:46:39</td>\n",
       "      <td>13.474100</td>\n",
       "      <td>55.247833</td>\n",
       "      <td>57.247799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>-0.014843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.480001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>0 days 16:53:13</td>\n",
       "      <td>0 days 19:03:27</td>\n",
       "      <td>Bike</td>\n",
       "      <td>no hr collected</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1915039748</td>\n",
       "      <td>2018-10-19 17:00:53</td>\n",
       "      <td>Spazierfahrt</td>\n",
       "      <td>Ride</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 01:17:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>activities/1915039748.gpx</td>\n",
       "      <td>0 days 00:10:38</td>\n",
       "      <td>2.577500</td>\n",
       "      <td>10.254230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0.034918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0 days 17:00:53</td>\n",
       "      <td>0 days 18:18:49</td>\n",
       "      <td>Bike</td>\n",
       "      <td>no hr collected</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918768385</td>\n",
       "      <td>2018-10-21 13:29:33</td>\n",
       "      <td>5km Training</td>\n",
       "      <td>Run</td>\n",
       "      <td>Mit Dorle</td>\n",
       "      <td>0 days 00:36:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>activities/1918768385.gpx</td>\n",
       "      <td>0 days 00:36:16</td>\n",
       "      <td>5.062400</td>\n",
       "      <td>38.321098</td>\n",
       "      <td>42.121101</td>\n",
       "      <td>5.6</td>\n",
       "      <td>32.900002</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>-0.075063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>407.491119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5102.299805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>0 days 13:29:33</td>\n",
       "      <td>0 days 14:05:59</td>\n",
       "      <td>Run</td>\n",
       "      <td>no hr collected</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1920958723</td>\n",
       "      <td>2018-10-22 15:19:08</td>\n",
       "      <td>20km Training</td>\n",
       "      <td>Ride</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 01:13:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>activities/1920958723.gpx</td>\n",
       "      <td>0 days 01:02:05</td>\n",
       "      <td>22.481699</td>\n",
       "      <td>129.917618</td>\n",
       "      <td>132.917999</td>\n",
       "      <td>1.2</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>-0.013344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>0 days 15:19:08</td>\n",
       "      <td>0 days 16:32:11</td>\n",
       "      <td>Bike</td>\n",
       "      <td>no hr collected</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1921011074</td>\n",
       "      <td>2018-10-18 16:56:49</td>\n",
       "      <td>500m Swim</td>\n",
       "      <td>Swim</td>\n",
       "      <td>(50M10B 09:40Mins + 50M10B 10:15 Mins + 50M10B...</td>\n",
       "      <td>0 days 00:09:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:09:40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>0 days 16:56:49</td>\n",
       "      <td>0 days 17:06:29</td>\n",
       "      <td>Swim</td>\n",
       "      <td>no hr collected</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity id       activity date        activity name activity type  \\\n",
       "0   1913005302 2018-10-18 16:53:13  Fahrt zum Schwimmen          Ride   \n",
       "1   1915039748 2018-10-19 17:00:53         Spazierfahrt          Ride   \n",
       "2   1918768385 2018-10-21 13:29:33         5km Training           Run   \n",
       "3   1920958723 2018-10-22 15:19:08        20km Training          Ride   \n",
       "4   1921011074 2018-10-18 16:56:49            500m Swim          Swim   \n",
       "\n",
       "                                activity description    elapsed time  \\\n",
       "0                                                NaN 0 days 02:10:14   \n",
       "1                                                NaN 0 days 01:17:56   \n",
       "2                                          Mit Dorle 0 days 00:36:26   \n",
       "3                                                NaN 0 days 01:13:03   \n",
       "4  (50M10B 09:40Mins + 50M10B 10:15 Mins + 50M10B... 0 days 00:09:40   \n",
       "\n",
       "   relative effort                   filename     moving time   distance  \\\n",
       "0              NaN  activities/1913005302.gpx 0 days 00:46:39  13.474100   \n",
       "1              NaN  activities/1915039748.gpx 0 days 00:10:38   2.577500   \n",
       "2              NaN  activities/1918768385.gpx 0 days 00:36:16   5.062400   \n",
       "3              NaN  activities/1920958723.gpx 0 days 01:02:05  22.481699   \n",
       "4              NaN                        NaN 0 days 00:09:40   0.500000   \n",
       "\n",
       "   elevation gain  elevation loss  elevation low  elevation high  max grade  \\\n",
       "0       55.247833       57.247799            0.0       17.000000  16.200001   \n",
       "1       10.254230             NaN            4.5       12.300000   5.300000   \n",
       "2       38.321098       42.121101            5.6       32.900002   6.800000   \n",
       "3      129.917618      132.917999            1.2       32.500000  12.700000   \n",
       "4        0.000000             NaN            NaN             NaN        NaN   \n",
       "\n",
       "   avg grade  avg positive grade  avg negative grade  max cadence  \\\n",
       "0  -0.014843                 NaN                 NaN          NaN   \n",
       "1   0.034918                 NaN                 NaN          NaN   \n",
       "2  -0.075063                 NaN                 NaN          NaN   \n",
       "3  -0.013344                 NaN                 NaN          NaN   \n",
       "4   0.000000                 NaN                 NaN          NaN   \n",
       "\n",
       "   avg cadence  max heart rate  avg heart rate  avg watts    calories  \\\n",
       "0          NaN             NaN             NaN        NaN         NaN   \n",
       "1          NaN             NaN             NaN        NaN         NaN   \n",
       "2          NaN             NaN             NaN        NaN  407.491119   \n",
       "3          NaN             NaN             NaN        NaN         NaN   \n",
       "4          NaN             NaN             NaN        NaN         NaN   \n",
       "\n",
       "   max temperature  avg temperature  perceived relative effort  \\\n",
       "0              NaN              NaN                        NaN   \n",
       "1              NaN              NaN                        NaN   \n",
       "2              NaN              NaN                        NaN   \n",
       "3              NaN              NaN                        NaN   \n",
       "4              NaN              NaN                        NaN   \n",
       "\n",
       "   grade adjusted distance  pool length  avg grade adjusted pace  avg speed  \\\n",
       "0                      NaN          NaN                      NaN        NaN   \n",
       "1                      NaN          NaN                      NaN        NaN   \n",
       "2              5102.299805          NaN                      NaN        NaN   \n",
       "3                      NaN          NaN                      NaN        NaN   \n",
       "4                      NaN          NaN                      NaN        NaN   \n",
       "\n",
       "   max speed  avg elapsed speed       date      start time     finish time  \\\n",
       "0  42.480001                NaN 2018-10-18 0 days 16:53:13 0 days 19:03:27   \n",
       "1  34.200000                NaN 2018-10-19 0 days 17:00:53 0 days 18:18:49   \n",
       "2  16.200000                NaN 2018-10-21 0 days 13:29:33 0 days 14:05:59   \n",
       "3  81.000000                NaN 2018-10-22 0 days 15:19:08 0 days 16:32:11   \n",
       "4        NaN                NaN 2018-10-18 0 days 16:56:49 0 days 17:06:29   \n",
       "\n",
       "  sport avg heart rate zone training mode  \n",
       "0  Bike     no hr collected          None  \n",
       "1  Bike     no hr collected          None  \n",
       "2   Run     no hr collected          None  \n",
       "3  Bike     no hr collected          None  \n",
       "4  Swim     no hr collected          None  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_activs_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging `df_activs_raw` & `df_injuries` & `df_max_hr_limit` & `df_exert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging with the injuries dataframe\n",
    "\n",
    "df_activs_raw = df_activs_raw.merge(df_injuries, how='left', on=\"date\")   \n",
    "\n",
    "# Filling null values with zeros (meaning: no injury or sickness)\n",
    "df_activs_raw[\"injury description\"] =  df_activs_raw[\"injury description\"].fillna(0)\n",
    "df_activs_raw[\"event\"] = df_activs_raw[\"event\"].fillna(0)\n",
    "\n",
    "# merging again with max yearly heart rate data\n",
    "df_activs_raw = df_activs_raw.merge(df_max_hr_limit, how='inner', on=\"date\") \n",
    "\n",
    "\n",
    "# merging again with the dataframe holding perceived exertion (values only for year 2024)\n",
    "df_activs_raw = df_activs_raw.merge(df_exert, how='left', on=\"date\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8) Set index\n",
    "\n",
    "#Create column with ID of each activity\n",
    "df_activs_raw.set_index(\"activity id\", inplace=True)\n",
    "\n",
    "# dropping  one swim activity which makes no sense with the id 7051509222 (wrong entry)\n",
    "df_activs_raw.drop(index=7051509222, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity date</th>\n",
       "      <th>activity name</th>\n",
       "      <th>activity type</th>\n",
       "      <th>activity description</th>\n",
       "      <th>elapsed time</th>\n",
       "      <th>relative effort</th>\n",
       "      <th>filename</th>\n",
       "      <th>moving time</th>\n",
       "      <th>distance</th>\n",
       "      <th>elevation gain</th>\n",
       "      <th>elevation loss</th>\n",
       "      <th>elevation low</th>\n",
       "      <th>elevation high</th>\n",
       "      <th>max grade</th>\n",
       "      <th>avg grade</th>\n",
       "      <th>avg positive grade</th>\n",
       "      <th>avg negative grade</th>\n",
       "      <th>max cadence</th>\n",
       "      <th>avg cadence</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>avg heart rate</th>\n",
       "      <th>avg watts</th>\n",
       "      <th>calories</th>\n",
       "      <th>max temperature</th>\n",
       "      <th>avg temperature</th>\n",
       "      <th>perceived relative effort</th>\n",
       "      <th>grade adjusted distance</th>\n",
       "      <th>pool length</th>\n",
       "      <th>avg grade adjusted pace</th>\n",
       "      <th>avg speed</th>\n",
       "      <th>max speed</th>\n",
       "      <th>avg elapsed speed</th>\n",
       "      <th>date</th>\n",
       "      <th>start time</th>\n",
       "      <th>finish time</th>\n",
       "      <th>sport</th>\n",
       "      <th>avg heart rate zone</th>\n",
       "      <th>training mode</th>\n",
       "      <th>event</th>\n",
       "      <th>injury description</th>\n",
       "      <th>max heart rate yearly</th>\n",
       "      <th>perceived exertion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1755</td>\n",
       "      <td>1755</td>\n",
       "      <td>1755</td>\n",
       "      <td>458</td>\n",
       "      <td>1755</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>1698</td>\n",
       "      <td>1755</td>\n",
       "      <td>1752.000000</td>\n",
       "      <td>1655.000000</td>\n",
       "      <td>1415.000000</td>\n",
       "      <td>1445.000000</td>\n",
       "      <td>1445.000000</td>\n",
       "      <td>1698.000000</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>1512.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>1698.000000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>1755</td>\n",
       "      <td>1755</td>\n",
       "      <td>1755</td>\n",
       "      <td>1755</td>\n",
       "      <td>1755</td>\n",
       "      <td>0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>1755.000000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>717</td>\n",
       "      <td>4</td>\n",
       "      <td>421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Morning Ride</td>\n",
       "      <td>Ride</td>\n",
       "      <td>Power Workout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>activities/1913005302.gpx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bike</td>\n",
       "      <td>no hr collected</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>710</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>912</td>\n",
       "      <td>1113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021-08-06 22:52:47.764672256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 01:12:02.067236467</td>\n",
       "      <td>42.926506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:41:48.634757834</td>\n",
       "      <td>12.023686</td>\n",
       "      <td>80.942420</td>\n",
       "      <td>188.675991</td>\n",
       "      <td>27.085052</td>\n",
       "      <td>58.894187</td>\n",
       "      <td>6.353636</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.244086</td>\n",
       "      <td>59.437172</td>\n",
       "      <td>151.492268</td>\n",
       "      <td>113.042018</td>\n",
       "      <td>120.270578</td>\n",
       "      <td>395.269021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.058824</td>\n",
       "      <td>215.107143</td>\n",
       "      <td>7042.919295</td>\n",
       "      <td>35.606061</td>\n",
       "      <td>3.107010</td>\n",
       "      <td>14.403265</td>\n",
       "      <td>27.636735</td>\n",
       "      <td>10.832994</td>\n",
       "      <td>2021-08-06 08:53:20</td>\n",
       "      <td>0 days 13:59:27.764672364</td>\n",
       "      <td>0 days 14:51:48.293447293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.407407</td>\n",
       "      <td>6.781991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2018-10-18 16:49:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>-14.500000</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.982808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.836105</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>351.200012</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.018960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-10-18 00:00:00</td>\n",
       "      <td>0 days 00:15:04</td>\n",
       "      <td>0 days 00:25:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019-12-17 12:06:18.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:14:17.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:12:59.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.733335</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>1.304812</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.644117</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>109.365715</td>\n",
       "      <td>82.775219</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>5018.599854</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.890249</td>\n",
       "      <td>3.513665</td>\n",
       "      <td>14.997600</td>\n",
       "      <td>3.019986</td>\n",
       "      <td>2019-12-17 00:00:00</td>\n",
       "      <td>0 days 10:31:02</td>\n",
       "      <td>0 days 11:47:10.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2021-07-11 13:34:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:24:57</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:21:52</td>\n",
       "      <td>5.536500</td>\n",
       "      <td>26.959047</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>80.351906</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>121.801830</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>135.500000</td>\n",
       "      <td>5082.100098</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.118327</td>\n",
       "      <td>11.417393</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>6.699661</td>\n",
       "      <td>2021-07-11 00:00:00</td>\n",
       "      <td>0 days 15:46:07</td>\n",
       "      <td>0 days 16:25:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-03-04 17:59:34.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:50:36</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:42:35.500000</td>\n",
       "      <td>10.022650</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>211.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>83.919464</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>152.294907</td>\n",
       "      <td>148.638218</td>\n",
       "      <td>463.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>7955.449951</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.373449</td>\n",
       "      <td>21.816001</td>\n",
       "      <td>39.239999</td>\n",
       "      <td>13.081679</td>\n",
       "      <td>2023-03-04 00:00:00</td>\n",
       "      <td>0 days 17:25:30</td>\n",
       "      <td>0 days 17:57:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-02-11 19:12:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 days 02:01:58</td>\n",
       "      <td>673.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 10:43:46</td>\n",
       "      <td>183.640859</td>\n",
       "      <td>2660.000000</td>\n",
       "      <td>2674.000000</td>\n",
       "      <td>1173.599976</td>\n",
       "      <td>2077.199951</td>\n",
       "      <td>49.908257</td>\n",
       "      <td>3.732971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>100.789169</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>186.734299</td>\n",
       "      <td>313.335968</td>\n",
       "      <td>3927.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1472.000000</td>\n",
       "      <td>43289.601562</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.837681</td>\n",
       "      <td>37.021011</td>\n",
       "      <td>83.879997</td>\n",
       "      <td>36.223287</td>\n",
       "      <td>2025-02-11 00:00:00</td>\n",
       "      <td>0 days 23:23:47</td>\n",
       "      <td>0 days 23:34:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 12:16:52.449164728</td>\n",
       "      <td>57.804968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 01:06:13.113021624</td>\n",
       "      <td>20.945589</td>\n",
       "      <td>230.765121</td>\n",
       "      <td>336.872602</td>\n",
       "      <td>125.564016</td>\n",
       "      <td>216.682082</td>\n",
       "      <td>8.273871</td>\n",
       "      <td>0.237563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.708839</td>\n",
       "      <td>27.990606</td>\n",
       "      <td>17.689467</td>\n",
       "      <td>54.777735</td>\n",
       "      <td>44.814866</td>\n",
       "      <td>488.288285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.757349</td>\n",
       "      <td>316.776278</td>\n",
       "      <td>4895.227812</td>\n",
       "      <td>12.547259</td>\n",
       "      <td>0.385006</td>\n",
       "      <td>10.278281</td>\n",
       "      <td>16.308492</td>\n",
       "      <td>10.255629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 04:17:43.447287324</td>\n",
       "      <td>0 days 04:07:10.614460995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.725736</td>\n",
       "      <td>1.904845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        activity date activity name activity type  \\\n",
       "count                            1755          1755          1755   \n",
       "unique                            NaN           717             4   \n",
       "top                               NaN  Morning Ride          Ride   \n",
       "freq                              NaN           178           710   \n",
       "mean    2021-08-06 22:52:47.764672256           NaN           NaN   \n",
       "min               2018-10-18 16:49:00           NaN           NaN   \n",
       "25%        2019-12-17 12:06:18.500000           NaN           NaN   \n",
       "50%               2021-07-11 13:34:04           NaN           NaN   \n",
       "75%        2023-03-04 17:59:34.500000           NaN           NaN   \n",
       "max               2025-02-11 19:12:17           NaN           NaN   \n",
       "std                               NaN           NaN           NaN   \n",
       "\n",
       "       activity description               elapsed time  relative effort  \\\n",
       "count                   458                       1755       830.000000   \n",
       "unique                  421                        NaN              NaN   \n",
       "top           Power Workout                        NaN              NaN   \n",
       "freq                     11                        NaN              NaN   \n",
       "mean                    NaN  0 days 01:12:02.067236467        42.926506   \n",
       "min                     NaN            0 days 00:00:18         0.000000   \n",
       "25%                     NaN     0 days 00:14:17.500000         5.000000   \n",
       "50%                     NaN            0 days 00:24:57        22.000000   \n",
       "75%                     NaN            0 days 00:50:36        60.000000   \n",
       "max                     NaN           21 days 02:01:58       673.000000   \n",
       "std                     NaN  0 days 12:16:52.449164728        57.804968   \n",
       "\n",
       "                         filename                moving time     distance  \\\n",
       "count                        1698                       1755  1752.000000   \n",
       "unique                       1698                        NaN          NaN   \n",
       "top     activities/1913005302.gpx                        NaN          NaN   \n",
       "freq                            1                        NaN          NaN   \n",
       "mean                          NaN  0 days 00:41:48.634757834    12.023686   \n",
       "min                           NaN            0 days 00:00:14     0.000000   \n",
       "25%                           NaN     0 days 00:12:59.500000     2.000000   \n",
       "50%                           NaN            0 days 00:21:52     5.536500   \n",
       "75%                           NaN     0 days 00:42:35.500000    10.022650   \n",
       "max                           NaN            0 days 10:43:46   183.640859   \n",
       "std                           NaN  0 days 01:06:13.113021624    20.945589   \n",
       "\n",
       "        elevation gain  elevation loss  elevation low  elevation high  \\\n",
       "count      1655.000000     1415.000000    1445.000000     1445.000000   \n",
       "unique             NaN             NaN            NaN             NaN   \n",
       "top                NaN             NaN            NaN             NaN   \n",
       "freq               NaN             NaN            NaN             NaN   \n",
       "mean         80.942420      188.675991      27.085052       58.894187   \n",
       "min           0.000000       -2.900000     -14.500000       -2.200000   \n",
       "25%           0.000000        1.733335       3.400000       11.900000   \n",
       "50%          26.959047       78.000000       5.400000       16.400000   \n",
       "75%          59.000000      211.500000      10.000000       28.000000   \n",
       "max        2660.000000     2674.000000    1173.599976     2077.199951   \n",
       "std         230.765121      336.872602     125.564016      216.682082   \n",
       "\n",
       "          max grade    avg grade  avg positive grade  avg negative grade  \\\n",
       "count   1698.000000  1755.000000                 0.0                 0.0   \n",
       "unique          NaN          NaN                 NaN                 NaN   \n",
       "top             NaN          NaN                 NaN                 NaN   \n",
       "freq            NaN          NaN                 NaN                 NaN   \n",
       "mean       6.353636     0.011376                 NaN                 NaN   \n",
       "min        0.000000    -3.982808                 NaN                 NaN   \n",
       "25%        1.304812    -0.004073                 NaN                 NaN   \n",
       "50%        4.200000     0.000000                 NaN                 NaN   \n",
       "75%        7.400000     0.034940                 NaN                 NaN   \n",
       "max       49.908257     3.732971                 NaN                 NaN   \n",
       "std        8.273871     0.237563                 NaN                 NaN   \n",
       "\n",
       "        max cadence  avg cadence  max heart rate  avg heart rate   avg watts  \\\n",
       "count    930.000000   961.000000      388.000000     1001.000000  454.000000   \n",
       "unique          NaN          NaN             NaN             NaN         NaN   \n",
       "top             NaN          NaN             NaN             NaN         NaN   \n",
       "freq            NaN          NaN             NaN             NaN         NaN   \n",
       "mean      72.244086    59.437172      151.492268      113.042018  120.270578   \n",
       "min       20.000000     0.000000       90.000000        0.000000   21.836105   \n",
       "25%       31.000000    28.644117      141.000000      109.365715   82.775219   \n",
       "50%       87.000000    80.351906      151.000000      129.000000  121.801830   \n",
       "75%      103.000000    83.919464      164.000000      152.294907  148.638218   \n",
       "max      172.000000   100.789169      188.000000      186.734299  313.335968   \n",
       "std       36.708839    27.990606       17.689467       54.777735   44.814866   \n",
       "\n",
       "           calories  max temperature  avg temperature  \\\n",
       "count   1512.000000              0.0        51.000000   \n",
       "unique          NaN              NaN              NaN   \n",
       "top             NaN              NaN              NaN   \n",
       "freq            NaN              NaN              NaN   \n",
       "mean     395.269021              NaN        13.058824   \n",
       "min        2.000000              NaN        -7.000000   \n",
       "25%      110.000000              NaN         8.000000   \n",
       "50%      281.000000              NaN        15.000000   \n",
       "75%      463.250000              NaN        19.000000   \n",
       "max     3927.000000              NaN        27.000000   \n",
       "std      488.288285              NaN         7.757349   \n",
       "\n",
       "        perceived relative effort  grade adjusted distance  pool length  \\\n",
       "count                   28.000000               363.000000    33.000000   \n",
       "unique                        NaN                      NaN          NaN   \n",
       "top                           NaN                      NaN          NaN   \n",
       "freq                          NaN                      NaN          NaN   \n",
       "mean                   215.107143              7042.919295    35.606061   \n",
       "min                     26.000000               351.200012    25.000000   \n",
       "25%                     59.250000              5018.599854    25.000000   \n",
       "50%                    135.500000              5082.100098    25.000000   \n",
       "75%                    198.000000              7955.449951    50.000000   \n",
       "max                   1472.000000             43289.601562    50.000000   \n",
       "std                    316.776278              4895.227812    12.547259   \n",
       "\n",
       "        avg grade adjusted pace    avg speed    max speed  avg elapsed speed  \\\n",
       "count                 40.000000  1366.000000  1698.000000         880.000000   \n",
       "unique                      NaN          NaN          NaN                NaN   \n",
       "top                         NaN          NaN          NaN                NaN   \n",
       "freq                        NaN          NaN          NaN                NaN   \n",
       "mean                   3.107010    14.403265    27.636735          10.832994   \n",
       "min                    2.018960     0.000000     0.000000           0.000000   \n",
       "25%                    2.890249     3.513665    14.997600           3.019986   \n",
       "50%                    3.118327    11.417393    29.700000           6.699661   \n",
       "75%                    3.373449    21.816001    39.239999          13.081679   \n",
       "max                    3.837681    37.021011    83.879997          36.223287   \n",
       "std                    0.385006    10.278281    16.308492          10.255629   \n",
       "\n",
       "                       date                 start time  \\\n",
       "count                  1755                       1755   \n",
       "unique                  NaN                        NaN   \n",
       "top                     NaN                        NaN   \n",
       "freq                    NaN                        NaN   \n",
       "mean    2021-08-06 08:53:20  0 days 13:59:27.764672364   \n",
       "min     2018-10-18 00:00:00            0 days 00:15:04   \n",
       "25%     2019-12-17 00:00:00            0 days 10:31:02   \n",
       "50%     2021-07-11 00:00:00            0 days 15:46:07   \n",
       "75%     2023-03-04 00:00:00            0 days 17:25:30   \n",
       "max     2025-02-11 00:00:00            0 days 23:23:47   \n",
       "std                     NaN  0 days 04:17:43.447287324   \n",
       "\n",
       "                      finish time sport avg heart rate zone training mode  \\\n",
       "count                        1755  1755                1755             0   \n",
       "unique                        NaN     3                   7             0   \n",
       "top                           NaN  Bike     no hr collected           NaN   \n",
       "freq                          NaN   912                1113           NaN   \n",
       "mean    0 days 14:51:48.293447293   NaN                 NaN           NaN   \n",
       "min               0 days 00:25:37   NaN                 NaN           NaN   \n",
       "25%        0 days 11:47:10.500000   NaN                 NaN           NaN   \n",
       "50%               0 days 16:25:40   NaN                 NaN           NaN   \n",
       "75%               0 days 17:57:57   NaN                 NaN           NaN   \n",
       "max               0 days 23:34:30   NaN                 NaN           NaN   \n",
       "std     0 days 04:07:10.614460995   NaN                 NaN           NaN   \n",
       "\n",
       "         event  injury description  max heart rate yearly  perceived exertion  \n",
       "count   1755.0              1755.0            1755.000000          211.000000  \n",
       "unique     7.0                11.0                    NaN                 NaN  \n",
       "top        0.0                 0.0                    NaN                 NaN  \n",
       "freq    1664.0              1664.0                    NaN                 NaN  \n",
       "mean       NaN                 NaN             191.407407            6.781991  \n",
       "min        NaN                 NaN             189.000000            3.000000  \n",
       "25%        NaN                 NaN             190.000000            5.000000  \n",
       "50%        NaN                 NaN             191.000000            7.000000  \n",
       "75%        NaN                 NaN             193.000000            8.000000  \n",
       "max        NaN                 NaN             194.000000           11.000000  \n",
       "std        NaN                 NaN               1.725736            1.904845  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9) Describe\n",
    "df_activs_raw.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10) Rearrange columns order \n",
    "\n",
    "#10a) create new colums for paces (we will fill them in a later step)\n",
    "\n",
    "df_activs_raw[\"swim pace\"] = None\n",
    "df_activs_raw[\"bike pace\"] = None\n",
    "df_activs_raw[\"run pace\"] = None\n",
    "\n",
    "df_activs_raw = df_activs_raw[[ 'date', 'activity date', 'sport', 'activity type', 'training mode', 'start time', 'moving time', 'elapsed time', 'finish time',  \n",
    "                             \n",
    "        'swim pace', 'bike pace', 'run pace',  'distance', 'grade adjusted distance', 'avg grade adjusted pace',\n",
    "        'avg heart rate', 'avg heart rate zone','max heart rate', 'max heart rate yearly',  'avg speed', 'max speed','avg elapsed speed',\n",
    "        'relative effort','calories','perceived exertion', \n",
    "        'pool length',\n",
    "    \n",
    "        'elevation gain', 'elevation loss', 'elevation low', 'elevation high', \n",
    "        'max grade', 'avg grade','avg positive grade', 'avg negative grade', \n",
    "        \n",
    "        'avg watts','avg cadence', 'max cadence', \n",
    "\n",
    "        'activity name', 'activity description',  \n",
    "        \n",
    "        'max temperature', 'avg temperature', 'perceived relative effort', \n",
    "        'event',  'injury description', \n",
    "      \n",
    "        'filename' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create subsets for each discipline\n",
    "df_activs_swim_raw =  df_activs_raw[df_activs_raw[\"activity type\"] == \"Swim\"] \n",
    "df_activs_run_raw =  df_activs_raw[df_activs_raw[\"activity type\"] == \"Run\" ]\n",
    "df_activs_bike_raw = df_activs_raw[df_activs_raw[\"activity type\"].isin([\"Ride\", \"Virtual Ride\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Swim Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWIM 💧\n",
    "#2a)Dropping unnecessary columns\n",
    "df_activs_swim_raw = df_activs_swim_raw.drop([\n",
    "'grade adjusted distance', 'avg grade adjusted pace', 'elevation gain', 'elevation loss', \n",
    "'elevation low', 'elevation high','max grade', 'avg grade', 'avg positive grade','avg negative grade', \n",
    "'avg watts', 'avg cadence', 'max cadence','max temperature','avg temperature',\n",
    "'perceived relative effort', \"avg elapsed speed\"\n",
    "], axis=1)\n",
    "\n",
    "#Create new column for swim pace which is normally measured in time per 100 meters\n",
    "df_activs_swim_raw[\"swim pace\"] = df_activs_swim_raw[\"moving time\"] / df_activs_swim_raw[\"distance\"] / 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving inherent problems in the swim dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Swim Activities that are actually part of one activity\n",
    "\n",
    "# PROBLEM: \n",
    "# The first years, I did not know that you could interrupt a swim activity on my fitness watch. \n",
    "# Therefore, whenever I took during a swim session a short break, I then afterwards started a new activity. \n",
    "# this, however, distorts the total amount of swim workouts I had\n",
    "\n",
    "# SOLUTION: \n",
    "# Step 1: Find days with more than one swim activity \n",
    "# Step 2: If these swim activities are shortly after each other, they belong to the same workout\n",
    "# Step 3: Merge (sum & average) the values in the columns together\n",
    "# Step 4: Create a dataframe with the merged swims (df_swims_singles_raw)\n",
    "# Step 5: Create dataframe for normal swims \n",
    "# Step 6: Combine both swim dataframes\n",
    "\n",
    "\n",
    "# Step 1: Find days with more than one swim activity \n",
    "df_filtered = df_activs_swim_raw[df_activs_swim_raw.groupby(\"date\")[\"date\"].transform(\"count\") > 1]\n",
    "\n",
    "# Step 2: If these swim activities are shortly after each other, they belong to the same workout \n",
    "# checked this manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/1505958361.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.drop(index=3121215271, inplace=True)\n",
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/1505958361.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.drop(index=3122793348, inplace=True)\n",
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/1505958361.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.drop(index=2681382064, inplace=True)\n",
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/1505958361.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.drop(index=2681382159, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 3) merge all activities except 3121215271 & 3122793348 as well as 2681382064 & 2681382159 🚧 🚧 🚧 🚧 🚧 🚧 🚧 🚧 \n",
    "# dropping the activities which are indeed individual activities \n",
    "df_filtered.drop(index=3121215271, inplace=True)\n",
    "df_filtered.drop(index=3122793348, inplace=True)\n",
    "df_filtered.drop(index=2681382064, inplace=True)\n",
    "df_filtered.drop(index=2681382159, inplace=True)\n",
    "\n",
    "# creating a dataframe that merges sum of the columns' values in one row per date\n",
    "df_filtered_merged_1 = df_filtered.groupby(\"date\")[[ \"moving time\",\"distance\"]].sum().reset_index()  # these are now the actual values of the combined activities\n",
    "\n",
    "# to also get the missing columns back (all expect date, moving time & distance), we just take the first activity per day\n",
    "df_filtered_merged_2= df_filtered.drop_duplicates(subset=\"date\", keep=\"first\")\n",
    "# now we also drop the columns where we have not the aggregated values \n",
    "df_filtered_merged_2 = df_filtered_merged_2.drop([\n",
    "    \"moving time\",\"elapsed time\",\"finish time\",\"distance\",\"avg speed\", \"max speed\", \"calories\", \"swim pace\",  \"activity name\", \"activity description\", \"filename\"  # swim pace? is that right? 🔴 🔴 🔴 🔴\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create a dataframe with the merged swims (df_swims_singles_raw)\n",
    "\n",
    "# Merging the two new placeholder dataframes as a substep\n",
    "df_filtered_merged_2 = df_filtered_merged_2.reset_index()\n",
    "df_swims_singles_raw = df_filtered_merged_1.merge(df_filtered_merged_2, how='outer')\n",
    "\n",
    "# reseting the index to activity id\n",
    "df_swims_singles_raw.set_index(\"activity id\", inplace=True)\n",
    "\n",
    "# Creating columns that `df_activs_swims_raw` has too but which are still missing here\n",
    "df_swims_singles_raw[\"elapsed time\"] = None\n",
    "df_swims_singles_raw[\"finish time\"] = None\n",
    "df_swims_singles_raw[\"max speed\"] = None\n",
    "df_swims_singles_raw[\"calories\"] = None\n",
    "df_swims_singles_raw[\"activity name\"] = None\n",
    "df_swims_singles_raw[\"activity description\"] = None\n",
    "df_swims_singles_raw[\"filename\"] = None\n",
    "\n",
    "\n",
    "df_swims_singles_raw[\"avg speed\"] =  None ### I should be able to calculate that, but skipped it for now \n",
    "df_swims_singles_raw[\"swim pace\"] = df_swims_singles_raw[\"moving time\"] / df_swims_singles_raw[\"distance\"] / 10   # again recreating the swim pace for the merged activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we do have one ready dataframe `df_swims_singles_raw` that holds all the merged swim activities that once where recorded separately even though they where one activity. But no we need to merge them with all the normal swims, that where properly recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create dataframe for normal swims \n",
    "\n",
    "## create a list of all activity ids of activities that are in the df_filtered \n",
    "df_filtered = df_filtered.reset_index()\n",
    "detached_swims_series = df_filtered[\"activity id\"]\n",
    "\n",
    "# creating a dataframe that only holds the \"normal\" swim activities that are properly recorded and not split up in separate activities\n",
    "df_swims_normals_raw = df_activs_swim_raw\n",
    "df_swims_normals_raw.drop(index=detached_swims_series, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/428099711.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_activs_swim_raw = pd.concat([df_swims_singles_raw, df_swims_normals_raw], axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Combine both swim dataframes\n",
    "\n",
    "\n",
    "# Rearranging the order of the column to be able to merge the two dataframes\n",
    "df_swims_normals_raw = df_swims_normals_raw[[ \"date\", \"activity date\", \"sport\", \"activity type\", \"training mode\", \"start time\", \"moving time\", \"elapsed time\", \n",
    "        \"finish time\",\"swim pace\", \"distance\", \"avg heart rate\", \"avg heart rate zone\", \"max heart rate\", \"max heart rate yearly\", \"avg speed\", \"max speed\", \n",
    "        \"relative effort\", \"calories\",'perceived exertion', \"pool length\", \"activity name\", \"activity description\",  'event', 'injury description', \"filename\"\n",
    " ]]\n",
    "\n",
    "df_swims_singles_raw = df_swims_singles_raw[[  \"date\", \"activity date\", \"sport\", \"activity type\",\"training mode\", \"start time\", \"moving time\", \"elapsed time\", \n",
    "        \"finish time\",\"swim pace\", \"distance\", \"avg heart rate\", \"avg heart rate zone\", \"max heart rate\", \"max heart rate yearly\", \"avg speed\", \"max speed\", \n",
    "        \"relative effort\", \"calories\",'perceived exertion', \"pool length\", \"activity name\", \"activity description\",  'event', 'injury description', \"filename\"\n",
    "]]\n",
    "\n",
    "# Finally concatting the two dataframes holding the normal swims and the merged swims\n",
    "df_activs_swim_raw = pd.concat([df_swims_singles_raw, df_swims_normals_raw], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Bike Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIKE 🚴‍♀️\n",
    "# Dropping unnecessary columns\n",
    "df_activs_bike_raw = df_activs_bike_raw.drop([\n",
    "'grade adjusted distance','avg grade adjusted pace', \n",
    "'pool length','avg positive grade','avg negative grade', \n",
    "'max temperature','avg temperature', 'perceived relative effort', 'swim pace', 'run pace'\n",
    "], axis=1)\n",
    "\n",
    "# Create new column for pace\n",
    "df_activs_bike_raw[\"bike pace\"] = df_activs_bike_raw[\"moving time\"]/df_activs_bike_raw[\"distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping `commute` rides to work and in town which were no proper workouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some bike rides are basically commutes in the town and not really proper activities. \n",
    "\n",
    "# drop all activities that have anything like \"commute\" or \"commuting\" in the title\n",
    "df_activs_bike_raw = df_activs_bike_raw[~df_activs_bike_raw[\"activity name\"].str.contains(\"Commut\", case=False, na=False)]\n",
    "\n",
    "\n",
    "# Since my way to work was around 6 km, I assume that all rides shorter than 7km are commutes, and therefore I make them a new dataframe\n",
    "df_activs_commutes_raw =  df_activs_bike_raw[df_activs_bike_raw[\"distance\"] < 7.0] \n",
    "\n",
    "# create a list of IDs of all commute activities \n",
    "df_activs_commutes_raw = df_activs_commutes_raw.reset_index()\n",
    "commute_id_list = df_activs_commutes_raw[\"activity id\"]\n",
    "\n",
    "# drop these commutes from the cycling dataframe  \n",
    "df_activs_bike_raw = df_activs_bike_raw.drop(index=commute_id_list, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping duplicate bike workouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates in the bike subset (SPECIFIC VERSION)\n",
    "\n",
    "# PROBLEM: \n",
    "# Activities are recorded on three different devices: Garmin Sport Watch, Wahoo Bike Computer and (sometimes) on the Whoop fitness tracker. \n",
    "# Hence, it could be that the same activity was uploaded twice but via different devices. \n",
    "\n",
    "# SOLUTION: \n",
    "# Step 1: Logic: Check days that have more than one activity of the same type on one day.\n",
    "# Step 2: If both of these activities have e.g. a similar distance, they are probably duplicates. \n",
    "# Step 3: Drop these\n",
    "\n",
    "# Since Swims were never recorded on two devices, and runs neither. I only check rides\n",
    "df_activs_bike_raw_filtered = df_activs_bike_raw[df_activs_bike_raw.groupby(\"date\")[\"date\"].transform(\"count\") > 1]\n",
    "# I then export this .csv and checked it manually for any inconsistencies and deleted the duplicates directly in the training platform (database) Strava and reimported them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Run Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 🏃‍♂️\n",
    "#2c)Dropping unnecessary columns\n",
    "df_activs_run_raw = df_activs_run_raw.drop([\n",
    "'pool length','avg positive grade','avg negative grade', \n",
    "'avg watts', 'max temperature',\n",
    "'avg temperature','perceived relative effort', 'bike pace', 'swim pace'\n",
    "], axis=1)\n",
    "\n",
    "# Create new column for pace (WORKING, BUT I DONT LIKE THE FORMAT)\n",
    "df_activs_run_raw[\"run pace\"] = df_activs_run_raw[\"moving time\"]/df_activs_run_raw[\"distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Saving the final Subset Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swims = df_activs_swim_raw\n",
    "df_bikes = df_activs_bike_raw\n",
    "df_runs = df_activs_run_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the subsets to csv. Uncomment to save 💾 💾 💾\n",
    "\n",
    "# saving to .csv\n",
    "'''\n",
    "df_swims.to_csv('df_swims.csv', index=True)\n",
    "df_bikes.to_csv('df_bikes.csv', index=True)\n",
    "df_runs.to_csv('df_runs.csv', index=True)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Saving the final Dataframes with all Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bringing the cleaned swim, bike, run subsets together in a all activity dataset `df_activs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sport-specific datasets do not have all the same columns. So I need to add the missing columns again, or I cant concat the three subsets again together\n",
    "\n",
    "# Create new empty columns in the swims subset\n",
    "df_activs_swim_raw[\"elevation gain\"] = None\n",
    "df_activs_swim_raw[\"elevation loss\"] = None\n",
    "df_activs_swim_raw[\"elevation low\"] = None\n",
    "df_activs_swim_raw[\"elevation high\"] = None\n",
    "df_activs_swim_raw[\"max grade\"] = None\n",
    "df_activs_swim_raw[\"avg grade\"] = None\n",
    "df_activs_swim_raw[\"avg watts\"] = None\n",
    "df_activs_swim_raw[\"avg cadence\"] = None\n",
    "df_activs_swim_raw[\"max cadence\"] = None\n",
    "df_activs_swim_raw[\"avg elapsed speed\"] = None\n",
    "#df_activs_swim_raw[\"perceived exertion\"] = None     # 🚨 you might want to delete this here, once you entered it above newly\n",
    "#df_activs_swim_raw[\"avg heart rate zone\"] = None        # 🚨 you might want to delete this here, once you entered it above newly\n",
    "df_activs_swim_raw[\"bike pace\"] = None \n",
    "df_activs_swim_raw[\"run pace\"] = None \n",
    "\n",
    "# Create new empty columns in the bike subset\n",
    "df_activs_bike_raw[\"pool length\"] = None\n",
    "#df_activs_bike_raw[\"perceived exertion\"] = None     # 🚨 you might want to delete this here, once you entered it above newly\n",
    "#df_activs_bike_raw[\"avg heart rate zone\"] = None        # 🚨 you might want to delete this here, once you entered it above newly\n",
    "df_activs_bike_raw[\"run pace\"] = None \n",
    "df_activs_bike_raw[\"swim pace\"] = None \n",
    "\n",
    "# Create new empty columns in the run subset\n",
    "df_activs_run_raw[\"pool length\"] = None\n",
    "df_activs_run_raw[\"avg watts\"] = None\n",
    "#df_activs_run_raw[\"perceived exertion\"] = None     # 🚨 you might want to delete this here, once you entered it above newly\n",
    "#df_activs_run_raw[\"avg heart rate zone\"] = None        # 🚨 you might want to delete this here, once you entered it above newly\n",
    "df_activs_run_raw[\"swim pace\"] = None \n",
    "df_activs_run_raw[\"bike pace\"] = None \n",
    "\n",
    "# Rearringing the order of columns in the three subsets\n",
    "df_activs_swim_raw = df_activs_swim_raw[[ 'date', 'activity date', 'sport', 'activity type', 'training mode', 'start time', 'moving time', 'elapsed time', 'finish time',                     \n",
    "        'swim pace', 'bike pace', 'run pace', 'distance', 'avg heart rate', 'avg heart rate zone', 'max heart rate',  \"max heart rate yearly\",  'avg speed', 'max speed','avg elapsed speed',\n",
    "        'relative effort','calories',\n",
    "        'pool length',\n",
    "        'elevation gain', 'elevation loss', 'elevation low', 'elevation high', \n",
    "        'max grade', 'avg grade',\n",
    "        'avg watts', 'avg cadence', 'max cadence', \n",
    "        'activity name', 'activity description', 'perceived exertion', 'event',  'injury description', \n",
    "        'filename' ]]\n",
    "\n",
    "df_activs_bike_raw = df_activs_bike_raw[[ 'date', 'activity date', 'sport', 'activity type', 'training mode', 'start time', 'moving time', 'elapsed time', 'finish time',                     \n",
    "         'swim pace', 'bike pace', 'run pace','distance', 'avg heart rate', 'avg heart rate zone', 'max heart rate', \"max heart rate yearly\",  'avg speed', 'max speed','avg elapsed speed',\n",
    "        'relative effort','calories',\n",
    "        'pool length',\n",
    "        'elevation gain', 'elevation loss', 'elevation low', 'elevation high', \n",
    "        'max grade', 'avg grade',\n",
    "        'avg watts', 'avg cadence', 'max cadence', \n",
    "        'activity name', 'activity description', 'perceived exertion', 'event',  'injury description', \n",
    "        'filename' ]]\n",
    "\n",
    "df_activs_run_raw = df_activs_run_raw[[ 'date', 'activity date', 'sport', 'activity type', 'training mode', 'start time', 'moving time', 'elapsed time', 'finish time',                     \n",
    "       'swim pace', 'bike pace', 'run pace', 'distance',  'avg heart rate', 'avg heart rate zone','max heart rate',  \"max heart rate yearly\", 'avg speed', 'max speed','avg elapsed speed',\n",
    "        'relative effort','calories',\n",
    "        'pool length',\n",
    "        'elevation gain', 'elevation loss', 'elevation low', 'elevation high', \n",
    "        'max grade', 'avg grade',\n",
    "        'avg watts', 'avg cadence', 'max cadence', \n",
    "        'activity name', 'activity description', 'perceived exertion','event',  'injury description', \n",
    "        'filename' ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/354823786.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_activs_concat1 = pd.concat([df_activs_swim_raw, df_activs_bike_raw], axis=0)\n",
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/354823786.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_activs_concats = pd.concat([df_activs_concat1, df_activs_run_raw], axis=0)\n",
      "/var/folders/1m/_v4c_fx94fv55ggvl5l850080000gn/T/ipykernel_26850/354823786.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_activs_concats = pd.concat([df_activs_concat1, df_activs_run_raw], axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Finally concatting the three dataframes into one set\n",
    "df_activs_concat1 = pd.concat([df_activs_swim_raw, df_activs_bike_raw], axis=0)\n",
    "df_activs_concats = pd.concat([df_activs_concat1, df_activs_run_raw], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Subsets to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating final dataframes\n",
    "\n",
    "df_activs = df_activs_concats\n",
    "\n",
    "# And saving it. Uncomment to save 💾 💾 💾\n",
    "'''\n",
    "df_activs.to_csv('df_activs.csv', index=True)  \n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
